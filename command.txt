                            Команды scrapy

    ЗАПУСК ОБОЛОЧКИ -- scrapy shell URL АДРЕС


    Запуск проекта -- scrapy startproject имя проекта
    Запуск паука -- scrapy crawl имя паука 
    scrapy crawl quotes -O quotes.json -- вывод данных ленты

shelp()- распечатать справку со списком доступных объектов и ярлыков

fetch(url[, redirect=True])— получить новый ответ с заданного URL-адреса и соответствующим образом обновить все связанные объекты.
    При желании вы можете попросить, чтобы перенаправления HTTP 3xx не выполнялись, передавredirect=False

fetch(request)- получить новый ответ на данный запрос и соответствующим образом обновить все связанные объекты.    

view(response)- откройте данный ответ в своем локальном веб-браузере для проверки. 
    Это добавит тег <base> в тело ответа, чтобы внешние ссылки (например, изображения и таблицы стилей) отображались правильно. 
    Однако учтите, что при этом на вашем компьютере будет создан временный файл, который не будет удален автоматически.


 




    crawler- текущий Crawlerобъект.

    spider- Паук, который, как известно, обрабатывает URL-адрес, или Spiderобъект, если для текущего URL-адреса не найден паук.

    request- Requestобъект последней выбранной страницы. Вы можете изменить этот запрос, используя replace()или получить новый запрос (не выходя из оболочки), используя fetchярлык.

    response- Responseобъект, содержащий последнюю полученную страницу

    settings- текущие настройки Scrapy


Иногда вы хотите проверить ответы, которые обрабатываются в определенной точке вашего паука, хотя бы для того, чтобы проверить, что ответ, который вы ожидаете, поступает туда.

	Этого можно добиться с помощью scrapy.shell.inspect_responseфункции.
